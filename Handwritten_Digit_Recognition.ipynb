{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPT3ycNKzFqtwaXduuNmVCf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VeArGosling/Handwritten-Digit-Recognition_model/blob/main/Handwritten_Digit_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Код модели для распознавания рукописных цифр"
      ],
      "metadata": {
        "id": "hbESEC2NcOmO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Добавление библиотек"
      ],
      "metadata": {
        "id": "CFckyt2AeM96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.optimizers import SGD"
      ],
      "metadata": {
        "id": "p-KGn6xzeQE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Нормализация данных"
      ],
      "metadata": {
        "id": "XakPx-xkjFmR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load train and test dataset\n",
        "def load_dataset():\n",
        "  # load dataset\n",
        "  (trainX, trainY), (testX, testY) = mnist.load_data()\n",
        "  # reshape dataset to have a single channel\n",
        "  trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
        "  testX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
        "  # one hot encode target values\n",
        "  trainY = to_categorical(trainY)\n",
        "  testY = to_categorical(testY)\n",
        "  return trainX, trainY, testX, testY\n",
        "\n",
        "# scale pixels\n",
        "def prep_pixels(train, test):\n",
        "  # convert from integers to floats\n",
        "  train_norm = train.astype('float32')\n",
        "  test_norm = test.astype('float32')\n",
        "  # normalize to range 0-1\n",
        "  train_norm = train_norm / 255.0\n",
        "  test_norm = test_norm / 255.0\n",
        "  # return normalized images\n",
        "  return train_norm, test_norm"
      ],
      "metadata": {
        "id": "nF8wPLGbeSV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Определение модели"
      ],
      "metadata": {
        "id": "fTnG7SBUjE6_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define cnn model\n",
        "def define_model():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "  # compile model\n",
        "  opt = SGD(learning_rate=0.01, momentum=0.9)\n",
        "  model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "NWRSwGsviwjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучение модели"
      ],
      "metadata": {
        "id": "5foRbECYjApy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# run the test harness for evaluating a model\n",
        "def run_test_harness():\n",
        "  # load dataset\n",
        "  trainX, trainY, testX, testY = load_dataset()\n",
        "  # prepare pixel data\n",
        "  trainX, testX = prep_pixels(trainX, testX)\n",
        "  # define model\n",
        "  model = define_model()\n",
        "  # fit model\n",
        "  model.fit(trainX, trainY, epochs=10, batch_size=32, verbose=1)\n",
        "  # save model\n",
        "  model.save('digit_model.h5')\n",
        "  _, acc = model.evaluate(testX, testY, verbose=0)\n",
        "  print('> %.3f' % (acc * 100.0))\n",
        "\n",
        "# entry point, run the test harness\n",
        "run_test_harness()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klg_R5iaizG2",
        "outputId": "92fa40db-1346-4d77-b980-b40c64ddbfe0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 41ms/step - accuracy: 0.9129 - loss: 0.2764\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 41ms/step - accuracy: 0.9855 - loss: 0.0466\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 39ms/step - accuracy: 0.9899 - loss: 0.0320\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 39ms/step - accuracy: 0.9929 - loss: 0.0217\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 40ms/step - accuracy: 0.9937 - loss: 0.0188\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 39ms/step - accuracy: 0.9961 - loss: 0.0127\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 40ms/step - accuracy: 0.9970 - loss: 0.0087\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 40ms/step - accuracy: 0.9975 - loss: 0.0071\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 40ms/step - accuracy: 0.9982 - loss: 0.0053\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 40ms/step - accuracy: 0.9986 - loss: 0.0048\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> 99.110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.ndimage.measurements import center_of_mass\n",
        "import math\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def getBestShift(img):\n",
        "    cy,cx = center_of_mass(img)\n",
        "\n",
        "    rows,cols = img.shape\n",
        "    shiftx = np.round(cols/2.0-cx).astype(int)\n",
        "    shifty = np.round(rows/2.0-cy).astype(int)\n",
        "\n",
        "    return shiftx,shifty\n",
        "\n",
        "def shift(img,sx,sy):\n",
        "    rows,cols = img.shape\n",
        "    M = np.float32([[1,0,sx],[0,1,sy]])\n",
        "    shifted = cv2.warpAffine(img,M,(cols,rows))\n",
        "    return shifted\n",
        "\n",
        "def rec_digit(img_path):\n",
        "  img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "  gray = 255-img\n",
        "  # применяем пороговую обработку\n",
        "  (thresh, gray) = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
        "\n",
        "  # удаляем нулевые строки и столбцы\n",
        "  while np.sum(gray[0]) == 0:\n",
        "    gray = gray[1:]\n",
        "  while np.sum(gray[:,0]) == 0:\n",
        "    gray = np.delete(gray,0,1)\n",
        "  while np.sum(gray[-1]) == 0:\n",
        "    gray = gray[:-1]\n",
        "  while np.sum(gray[:,-1]) == 0:\n",
        "    gray = np.delete(gray,-1,1)\n",
        "  rows,cols = gray.shape\n",
        "\n",
        "  # изменяем размер, чтобы помещалось в box 20x20 пикселей\n",
        "  if rows > cols:\n",
        "    factor = 20.0/rows\n",
        "    rows = 20\n",
        "    cols = int(round(cols*factor))\n",
        "    gray = cv2.resize(gray, (cols,rows))\n",
        "  else:\n",
        "    factor = 20.0/cols\n",
        "    cols = 20\n",
        "    rows = int(round(rows*factor))\n",
        "    gray = cv2.resize(gray, (cols, rows))\n",
        "\n",
        "  # расширяем до размера 28x28\n",
        "  colsPadding = (int(math.ceil((28-cols)/2.0)),int(math.floor((28-cols)/2.0)))\n",
        "  rowsPadding = (int(math.ceil((28-rows)/2.0)),int(math.floor((28-rows)/2.0)))\n",
        "  gray = np.lib.pad(gray,(rowsPadding,colsPadding),'constant')\n",
        "\n",
        "  # сдвигаем центр масс\n",
        "  shiftx,shifty = getBestShift(gray)\n",
        "  shifted = shift(gray,shiftx,shifty)\n",
        "  gray = shifted\n",
        "\n",
        "  cv2.imwrite('gray'+ img_path, gray)\n",
        "  img = gray / 255.0\n",
        "  img = np.array(img).reshape(-1, 28, 28, 1)\n",
        "  out = str(np.argmax(model.predict(img)))\n",
        "  return out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E197c8pMqw19",
        "outputId": "fd64aeab-5f05-442b-bacf-e0d33ff7ea3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-c4c1d99a8a43>:1: DeprecationWarning: Please import `center_of_mass` from the `scipy.ndimage` namespace; the `scipy.ndimage.measurements` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
            "  from scipy.ndimage.measurements import center_of_mass\n"
          ]
        }
      ]
    }
  ]
}